
from fastapi import APIRouter, Body
from app.services.conversation_service import conversation_service
from app.services.semantic_memory import semantic_memory
from app.services.memory_service import memory_service
from app.services.llm_service import llm_service

router = APIRouter()

@router.post("/chat/query")
async def chat_query(text: str = Body(..., embed=True)):
    """
    Process a text query.
    Uses Semantic Vector Search + Server-Side Context.
    """
    text = text.strip()
    lower_text = text.lower()
    
    # 1. Retrieve Context
    context = conversation_service.get_context()
    context_name = context.get("name") if context else None
    
    # 2. Check for Follow-up ("he", "she", "where", "look")
    pronouns = ["he", "she", "him", "her", "it", "his", "her", "live", "do", "does", "about", "look", "features"]
    is_followup = any(p in lower_text.split() for p in pronouns)
    
    matches = []
    
    # SAFETY: If user says "He" but we don't know who "He" is (Context is None)
    if is_followup and not context_name and "who is" not in lower_text:
         return {
             "status": "unknown",
             "text": "I'm not sure who you are referring to. Who are we talking about?"
         }
    
    
    # 0. Direct Entity Search (Person/Object Name)
    entity_matches = memory_service.search_by_text(text)
    if entity_matches:
        # High confidence match on name
        print(f"Direct Entity Match: {entity_matches[0].payload.get('name')}")
        payload = entity_matches[0].payload
        name = payload.get("name")
        # Construct text using LLM
        desc = llm_service.generate_response(user_text=text, context=payload)
        matches = [{"name": name, "text": desc, "score": 1.0, "payload": payload}]
    elif context_name and is_followup and "who is" not in lower_text:
        # Contextual Search: Filter by current person
        # e.g. "How does he look?" -> Search "How does he look" filtered by name="Emraan"
        print(f"Context Search for {context_name}: {text}")
        matches = semantic_memory.search_knowledge(text, context_name=context_name)
    else:
        # Global Search
        # e.g. "Who is Emraan?" or "Find the doctor"
        print(f"Global Search: {text}")
        matches = semantic_memory.search_knowledge(text)
    
    if matches:
        best_match = matches[0] # Payload from semantic memory (Text only)
        text_content = best_match.get("text") or f"I found a memory about {best_match.get('name', 'them')}."
        name = best_match.get("name")
        
        full_person = None
        audio_base64 = None
        image_base64 = None
        original_matches = []
        
        if name:
             # Update: Always search to get Gallery/Duplicates
             original_matches = memory_service.search_by_text(name)
             if original_matches:
                 full_person = original_matches[0].payload
                 
                 # MERGING: Scan all matches to find Audio/Image if missing in top match
                 for m in original_matches:
                     if not audio_base64 and m.payload.get("audio_base64"):
                         audio_base64 = m.payload.get("audio_base64")
                     if not image_base64 and m.payload.get("image_base64"):
                         image_base64 = m.payload.get("image_base64")
             else:
                  # Fallback if search fails but name exists (rare)
                  full_person = matches[0].get("payload")
             
             if full_person:
                 if not audio_base64: audio_base64 = full_person.get("audio_base64")
                 if not image_base64: image_base64 = full_person.get("image_base64")
                 
                 # Handle Object Location response
                 if full_person.get("type") == "object":
                     location = full_person.get("location", "unknown place")
                     # text_content is now generated by LLM below

        # Update Context
        if full_person:
            conversation_service.update_context(full_person)
        else:
             conversation_service.update_context(best_match)
        
        # Prepare context for LLM
        llm_context = full_person if full_person else best_match
        if llm_context:
            llm_context["has_audio"] = bool(audio_base64)
            llm_context["has_image"] = bool(image_base64)

        # Generate Response via LLM
        final_text = llm_service.generate_response(user_text=text, context=llm_context)

        # Build Gallery (Always helpful for identity)
        gallery = []
        if original_matches:
             seen_imgs = set()
             for m in original_matches:
                 img = m.payload.get("image_base64")
                 if img and len(img) > 100 and img not in seen_imgs:
                     gallery.append(img)
                     seen_imgs.add(img)
             gallery = gallery[:6]

        # Intent Filtering
        # Only send audio if user specifically asks for it
        voice_keywords = ["voice", "talk", "speak", "sound", "listen", "hear"]
        voice_intent = any(k in text.lower() for k in voice_keywords)
        final_audio = audio_base64 if voice_intent else None

        # Only send gallery if user specifically asks for it
        gallery_keywords = ["memories", "photos", "pictures", "images", "gallery", "album", "see", "look"]
        gallery_intent = any(k in text.lower() for k in gallery_keywords)
        final_gallery = gallery if gallery_intent else []

        # SERVER-SIDE TTS (Pygame) - DISABLED (User Request: Web Voice Only)
        # try:
        #     from app.services.tts_service import tts_service
        #     import asyncio
        #     asyncio.create_task(tts_service.speak(final_text))
        # except Exception as e:
        #     print(f"TTS Trigger Failed: {e}")

        response_data = {
            "status": "found",
            "text": final_text,
            "person": full_person if full_person else best_match,
            "audio_base64": final_audio,
            "image_base64": image_base64,
            "gallery": final_gallery
        }
        print(f"DEBUG RESPONSE: IntentVoice={voice_intent} IntentGallery={gallery_intent} Audio={bool(final_audio)} Gallery={len(final_gallery)}")
        return response_data

    return {
        "status": "unknown",
        "text": "I couldn't find anything relevant in my memory."
    }
